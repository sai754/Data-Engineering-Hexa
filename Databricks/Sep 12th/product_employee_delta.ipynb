{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e73bd6e9-6920-4629-840d-78ce176c86b3",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products before delete operation\n+-----------+-----+---------+-----------+-----+\n|   Category|Price|ProductID|ProductName|Stock|\n+-----------+-----+---------+-----------+-----+\n|Electronics| 1200|      101|     Laptop|   35|\n|Electronics|  800|      102| Smartphone|   80|\n|  Furniture|  150|      103| Desk Chair|   60|\n|Electronics|  300|      104|    Monitor|   45|\n|  Furniture|  350|      105|       Desk|   25|\n+-----------+-----+---------+-----------+-----+\n\nEmployees before update operation\n+----------+-------------+----------+-----------+------+\n|EmployeeID|         Name|Department|JoiningDate|Salary|\n+----------+-------------+----------+-----------+------+\n|      1001|     John Doe|        HR| 2021-01-15| 55000|\n|      1002|   Jane Smith|        IT| 2020-03-10| 62000|\n|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n|      1004|Michael Brown|        HR| 2018-12-22| 54000|\n|      1005| David Wilson|        IT| 2021-06-25| 58000|\n|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n|      1007| James Miller|        IT| 2019-08-14| 65000|\n|      1008|Barbara Moore|        HR| 2021-03-29| 53000|\n+----------+-------------+----------+-----------+------+\n\n+----------+-------------+----------+-----------+------+\n|EmployeeID|         Name|Department|JoiningDate|Salary|\n+----------+-------------+----------+-----------+------+\n|      1003|Emily Johnson|   Finance| 2019-07-01| 70000|\n|      1006|  Linda Davis|   Finance| 2020-11-15| 67000|\n+----------+-------------+----------+-----------+------+\n\n+-----------+-----+---------+-----------+-----+\n|   Category|Price|ProductID|ProductName|Stock|\n+-----------+-----+---------+-----------+-----+\n|Electronics|  800|      102| Smartphone|   80|\n+-----------+-----+---------+-----------+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/product_data.json\", \"dbfs:/FileStore/product_data.json\")\n",
    "\n",
    "dbutils.fs.cp(\"file:/Workspace/Shared/employee_data.csv\", \"dbfs:/FileStore/employee_data.csv\")\n",
    "\n",
    "product_df = spark.read.option(\"multiline\", \"true\").json(\"/FileStore/product_data.json\") \n",
    "\n",
    "employee_df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"/FileStore/employee_data.csv\")\n",
    "\n",
    "# Converting CSV and JSON to delta format\n",
    "\n",
    "employee_df.write.format(\"delta\").mode(\"overwrite\").save(\"/Workspace/Shared/employee_table\")\n",
    "\n",
    "product_df.write.format(\"delta\").mode(\"overwrite\").save(\"/Workspace/Shared/product_table\")\n",
    "\n",
    "# Register Delta Tables\n",
    "\n",
    "# employee_df.write.saveAsTable(\"employee_table\")\n",
    "# product_df.write.saveAsTable(\"products_table\")\n",
    "\n",
    "employee_delta_path = \"/Workspace/Shared/employee_table\"\n",
    "product_delta_path = \"/Workspace/Shared/product_table\"\n",
    "\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS employee_delta USING DELTA LOCATION '{employee_delta_path}'\")\n",
    "spark.sql(f\"CREATE TABLE IF NOT EXISTS product_delta USING DELTA LOCATION '{product_delta_path}'\")\n",
    "\n",
    "# Data modification\n",
    "\n",
    "# Increase the salary by 5% for all employees in the IT department.\n",
    "spark.sql(\"update employee_delta set Salary = Salary * 1.05 where Department = 'IT'\")\n",
    "\n",
    "#  Delete products where the stock is less than 40.\n",
    "spark.sql(\"delete from product_delta where Stock < 40\")\n",
    "\n",
    "# Time Travel \n",
    "\n",
    "print(\"Products before delete operation\")\n",
    "spark.sql(\"SELECT * FROM product_delta VERSION AS OF 0\").show()\n",
    "\n",
    "print(\"Employees before update operation\")\n",
    "spark.sql(\"SELECT * FROM employee_delta VERSION AS OF 0\").show()\n",
    "\n",
    "# Query Delta Tables\n",
    "\n",
    "# Query employees in finance department\n",
    "spark.sql(\"SELECT * FROM employee_delta WHERE Department = 'Finance'\").show()\n",
    "\n",
    "# Query Electronics products with price > 500\n",
    "spark.sql(\"SELECT * FROM product_delta WHERE Category = 'Electronics' AND Price > 500\").show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "product_employee_delta",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
